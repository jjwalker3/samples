{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import base packages into the namespace for this program\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# modeling routines from Scikit Learn packages\n",
    "import sklearn.linear_model \n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# scoring metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# seed value for random number generators to obtain reproducible results\n",
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read data for the Boston Housing Study\n",
    "boston_input = pd.read_csv('boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "boston DataFrame (first and last five rows):\n",
      "  neighborhood     crim    zn  indus  chas    nox  rooms   age     dis  rad  \\\n",
      "0       Nahant  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
      "1   Swampscott  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
      "2   Swanpscott  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
      "3   Marblehead  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
      "4   Marblehead  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
      "\n",
      "   tax  ptratio  lstat    mv  \n",
      "0  296     15.3   4.98  24.0  \n",
      "1  242     17.8   9.14  21.6  \n",
      "2  242     17.8   4.03  34.7  \n",
      "3  222     18.7   2.94  33.4  \n",
      "4  222     18.7   5.33  36.2  \n",
      "    neighborhood     crim   zn  indus  chas    nox  rooms   age     dis  rad  \\\n",
      "501     Winthrop  0.06263  0.0  11.93     0  0.573  6.593  69.1  2.4786    1   \n",
      "502     Winthrop  0.04527  0.0  11.93     0  0.573  6.120  76.7  2.2875    1   \n",
      "503     Winthrop  0.06076  0.0  11.93     0  0.573  6.976  91.0  2.1675    1   \n",
      "504     Winthrop  0.10959  0.0  11.93     0  0.573  6.794  89.3  2.3889    1   \n",
      "505     Winthrop  0.04741  0.0  11.93     0  0.573  6.030  80.8  2.5050    1   \n",
      "\n",
      "     tax  ptratio  lstat    mv  \n",
      "501  273     21.0   9.67  22.4  \n",
      "502  273     21.0   9.08  20.6  \n",
      "503  273     21.0   5.64  23.9  \n",
      "504  273     21.0   6.48  22.0  \n",
      "505  273     21.0   7.88  19.0  \n",
      "\n",
      "General description of the boston_input DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      "neighborhood    506 non-null object\n",
      "crim            506 non-null float64\n",
      "zn              506 non-null float64\n",
      "indus           506 non-null float64\n",
      "chas            506 non-null int64\n",
      "nox             506 non-null float64\n",
      "rooms           506 non-null float64\n",
      "age             506 non-null float64\n",
      "dis             506 non-null float64\n",
      "rad             506 non-null int64\n",
      "tax             506 non-null int64\n",
      "ptratio         506 non-null float64\n",
      "lstat           506 non-null float64\n",
      "mv              506 non-null float64\n",
      "dtypes: float64(10), int64(3), object(1)\n",
      "memory usage: 55.4+ KB\n",
      "None\n",
      "\n",
      "General description of the boston DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      "crim       506 non-null float64\n",
      "zn         506 non-null float64\n",
      "indus      506 non-null float64\n",
      "chas       506 non-null int64\n",
      "nox        506 non-null float64\n",
      "rooms      506 non-null float64\n",
      "age        506 non-null float64\n",
      "dis        506 non-null float64\n",
      "rad        506 non-null int64\n",
      "tax        506 non-null int64\n",
      "ptratio    506 non-null float64\n",
      "lstat      506 non-null float64\n",
      "mv         506 non-null float64\n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 51.5 KB\n",
      "None\n",
      "\n",
      "Descriptive statistics of the boston DataFrame:\n",
      "             crim          zn       indus        chas         nox       rooms  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              age         dis         rad         tax     ptratio       lstat  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
      "\n",
      "               mv  \n",
      "count  506.000000  \n",
      "mean    22.528854  \n",
      "std      9.182176  \n",
      "min      5.000000  \n",
      "25%     17.025000  \n",
      "50%     21.200000  \n",
      "75%     25.000000  \n",
      "max     50.000000  \n"
     ]
    }
   ],
   "source": [
    "# check the pandas DataFrame object boston_input\n",
    "print('\\nboston DataFrame (first and last five rows):')\n",
    "print(boston_input.head())\n",
    "print(boston_input.tail())\n",
    "\n",
    "print('\\nGeneral description of the boston_input DataFrame:')\n",
    "print(boston_input.info())\n",
    "\n",
    "# drop neighborhood from the data being considered\n",
    "boston = boston_input.drop('neighborhood', 1)\n",
    "print('\\nGeneral description of the boston DataFrame:')\n",
    "print(boston.info())\n",
    "\n",
    "print('\\nDescriptive statistics of the boston DataFrame:')\n",
    "print(boston.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set up preliminary data for data for fitting the models \n",
    "# the first column is the median housing value response\n",
    "# the remaining columns are the explanatory variables\n",
    "prelim_model_data = np.array([boston.mv,\\\n",
    "    boston.crim,\\\n",
    "    boston.zn,\\\n",
    "    boston.indus,\\\n",
    "    boston.chas,\\\n",
    "    boston.nox,\\\n",
    "    boston.rooms,\\\n",
    "    boston.age,\\\n",
    "    boston.dis,\\\n",
    "    boston.rad,\\\n",
    "    boston.tax,\\\n",
    "    boston.ptratio,\\\n",
    "    boston.lstat]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data dimensions: (506, 13)\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[  2.25288538e+01   3.61352356e+00   1.13636364e+01   1.11367787e+01\n",
      "   6.91699605e-02   5.54695059e-01   6.28463439e+00   6.85749012e+01\n",
      "   3.79504269e+00   9.54940711e+00   4.08237154e+02   1.84555336e+01\n",
      "   1.26530632e+01]\n",
      "[  9.17309810e+00   8.59304135e+00   2.32993957e+01   6.85357058e+00\n",
      "   2.53742935e-01   1.15763115e-01   7.01922514e-01   2.81210326e+01\n",
      "   2.10362836e+00   8.69865112e+00   1.68370495e+02   2.16280519e+00\n",
      "   7.13400164e+00]\n",
      "\n",
      "Dimensions for model_data: (506, 13)\n"
     ]
    }
   ],
   "source": [
    "# dimensions of the polynomial model X input and y response\n",
    "# preliminary data before standardization\n",
    "print('\\nData dimensions:', prelim_model_data.shape)\n",
    "\n",
    "# standard scores for the columns... along axis 0\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(prelim_model_data))\n",
    "# show standardization constants being employed\n",
    "print(scaler.mean_)\n",
    "print(scaler.scale_)\n",
    "\n",
    "# the model data will be standardized form of preliminary model data\n",
    "model_data = scaler.fit_transform(prelim_model_data)\n",
    "\n",
    "# dimensions of the polynomial model X input and y response\n",
    "# all in standardized units of measure\n",
    "print('\\nDimensions for model_data:', model_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set response and predictor variables for later fitting and testing\n",
    "Y = model_data[:,0]\n",
    "X = model_data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cross-fold validation (number of folds)\n",
    "K = 15\n",
    "# random_state value\n",
    "RANDO = 15\n",
    "# set intercept for models\n",
    "SET_FIT_INTERCEPT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define function for running GridSearch and producing optimal model\n",
    "def GridModeller(model,params):\n",
    "    model_grid = GridSearchCV(model,params,cv=K,scoring='neg_mean_squared_error')\n",
    "    model_grid.fit(X,Y)\n",
    "    cvres = model_grid.cv_results_\n",
    "    print(model_grid.best_estimator_)\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(np.sqrt(-mean_score), params)\n",
    "    return(model_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# OLS Regression\n",
    "Linear_Regression = LinearRegression(fit_intercept = SET_FIT_INTERCEPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='squared_loss', n_iter=5, penalty=None, power_t=0.25,\n",
      "       random_state=15, shuffle=True, verbose=0, warm_start=False)\n",
      "0.679020483328 {'eta0': 0.001, 'n_iter': 5, 'random_state': 15, 'penalty': None}\n",
      "0.589950207567 {'eta0': 0.001, 'n_iter': 50, 'random_state': 15, 'penalty': None}\n",
      "0.602992639461 {'eta0': 0.001, 'n_iter': 500, 'random_state': 15, 'penalty': None}\n",
      "0.58910493533 {'eta0': 0.01, 'n_iter': 5, 'random_state': 15, 'penalty': None}\n",
      "0.605357242104 {'eta0': 0.01, 'n_iter': 50, 'random_state': 15, 'penalty': None}\n",
      "0.607560730809 {'eta0': 0.01, 'n_iter': 500, 'random_state': 15, 'penalty': None}\n",
      "0.634802434455 {'eta0': 0.1, 'n_iter': 5, 'random_state': 15, 'penalty': None}\n",
      "0.618036076064 {'eta0': 0.1, 'n_iter': 50, 'random_state': 15, 'penalty': None}\n",
      "0.615516336707 {'eta0': 0.1, 'n_iter': 500, 'random_state': 15, 'penalty': None}\n",
      "904858292820.0 {'eta0': 1.0, 'n_iter': 5, 'random_state': 15, 'penalty': None}\n",
      "4.31431013316 {'eta0': 1.0, 'n_iter': 50, 'random_state': 15, 'penalty': None}\n",
      "0.751022703608 {'eta0': 1.0, 'n_iter': 500, 'random_state': 15, 'penalty': None}\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent Regression\n",
    "SGD_params = [\n",
    "    {'n_iter': [5,50,500],\n",
    "     'eta0': [0.001,0.01,0.1,1.0],\n",
    "     'penalty': [None],\n",
    "     'random_state' : [RANDO]\n",
    "    }]\n",
    "sgd_reg = SGDRegressor()\n",
    "SGD_Regression = GridModeller(sgd_reg,SGD_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=15, solver='auto', tol=0.001)\n",
      "0.607430074475 {'fit_intercept': True, 'alpha': 0.0001, 'normalize': False, 'random_state': 15}\n",
      "0.607429208906 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'random_state': 15}\n",
      "0.607420557011 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'random_state': 15}\n",
      "0.607334416259 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'random_state': 15}\n",
      "0.606509191539 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'random_state': 15}\n",
      "0.600769793266 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'random_state': 15}\n",
      "0.596711759275 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'random_state': 15}\n",
      "0.718144467879 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'random_state': 15}\n",
      "0.94055286509 {'fit_intercept': True, 'alpha': 10000, 'normalize': False, 'random_state': 15}\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regress\n",
    "ridge_params = [\n",
    "    {'alpha': [0.0001,0.001,0.01,0.1,1.0,10,100,1000,10000],\n",
    "     'fit_intercept': [SET_FIT_INTERCEPT],\n",
    "     'normalize': [False],\n",
    "     'random_state' : [RANDO]\n",
    "    }]\n",
    "ridge_reg = Ridge()\n",
    "Ridge_Regression = GridModeller(ridge_reg,ridge_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=15, solver='auto', tol=0.001)\n",
      "0.607430074475 {'fit_intercept': True, 'alpha': 0.0001, 'normalize': False, 'random_state': 15}\n",
      "0.607429208906 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'random_state': 15}\n",
      "0.607420557011 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'random_state': 15}\n",
      "0.607334416259 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'random_state': 15}\n",
      "0.606509191539 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'random_state': 15}\n",
      "0.600769793266 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'random_state': 15}\n",
      "0.596711759275 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'random_state': 15}\n",
      "0.718144467879 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'random_state': 15}\n",
      "0.94055286509 {'fit_intercept': True, 'alpha': 10000, 'normalize': False, 'random_state': 15}\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "lasso_params = [\n",
    "    {'alpha': [0.0001,0.001,0.01,0.1,1.0,10,100,1000,10000],\n",
    "     'fit_intercept': [SET_FIT_INTERCEPT],\n",
    "     'normalize': [False],\n",
    "     'random_state' : [RANDO]\n",
    "    }]\n",
    "lasso_reg = Ridge()\n",
    "Lasso_Regression = GridModeller(lasso_reg,lasso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.1,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=15, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "0.606946558639 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.1, 'random_state': 15}\n",
      "0.606908209789 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.2, 'random_state': 15}\n",
      "0.60687108597 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.3, 'random_state': 15}\n",
      "0.606832261809 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.4, 'random_state': 15}\n",
      "0.606791526277 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.5, 'random_state': 15}\n",
      "0.606752888245 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.6, 'random_state': 15}\n",
      "0.606714712073 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.7, 'random_state': 15}\n",
      "0.606676388091 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.8, 'random_state': 15}\n",
      "0.606641236375 {'fit_intercept': True, 'alpha': 0.001, 'normalize': False, 'l1_ratio': 0.9, 'random_state': 15}\n",
      "0.603503173991 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.1, 'random_state': 15}\n",
      "0.603459401535 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.2, 'random_state': 15}\n",
      "0.60369098922 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.3, 'random_state': 15}\n",
      "0.604114776105 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.4, 'random_state': 15}\n",
      "0.604689884734 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.5, 'random_state': 15}\n",
      "0.605404401996 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.6, 'random_state': 15}\n",
      "0.6062763029 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.7, 'random_state': 15}\n",
      "0.60695484231 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.8, 'random_state': 15}\n",
      "0.607292029677 {'fit_intercept': True, 'alpha': 0.01, 'normalize': False, 'l1_ratio': 0.9, 'random_state': 15}\n",
      "0.600291004173 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.1, 'random_state': 15}\n",
      "0.608627682784 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.2, 'random_state': 15}\n",
      "0.615900249162 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.3, 'random_state': 15}\n",
      "0.622859151963 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.4, 'random_state': 15}\n",
      "0.627829114486 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.5, 'random_state': 15}\n",
      "0.631345690773 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.6, 'random_state': 15}\n",
      "0.632638661102 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.7, 'random_state': 15}\n",
      "0.634249883341 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.8, 'random_state': 15}\n",
      "0.635793600935 {'fit_intercept': True, 'alpha': 0.1, 'normalize': False, 'l1_ratio': 0.9, 'random_state': 15}\n",
      "0.704819513269 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.1, 'random_state': 15}\n",
      "0.750829471998 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.2, 'random_state': 15}\n",
      "0.801158243896 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.3, 'random_state': 15}\n",
      "0.854633731002 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.4, 'random_state': 15}\n",
      "0.91035304732 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.5, 'random_state': 15}\n",
      "0.970973896764 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.6, 'random_state': 15}\n",
      "1.01762362422 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.7, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.8, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1.0, 'normalize': False, 'l1_ratio': 0.9, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.1, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.2, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.3, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.4, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.5, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.6, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.7, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.8, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 10, 'normalize': False, 'l1_ratio': 0.9, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.1, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.2, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.3, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.4, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.5, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.6, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.7, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.8, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 100, 'normalize': False, 'l1_ratio': 0.9, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.1, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.2, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.3, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.4, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.5, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.6, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.7, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.8, 'random_state': 15}\n",
      "1.03136306274 {'fit_intercept': True, 'alpha': 1000, 'normalize': False, 'l1_ratio': 0.9, 'random_state': 15}\n"
     ]
    }
   ],
   "source": [
    "# Elastic Regression\n",
    "elastic_params = [\n",
    "    {'alpha': [0.001,0.01,0.1,1.0,10,100,1000],\n",
    "     'fit_intercept': [SET_FIT_INTERCEPT],\n",
    "     'l1_ratio': [.1,.2,.3,.4,.5,.6,.7,.8,.9],\n",
    "     'normalize': [False],\n",
    "     'random_state' : [RANDO]\n",
    "    }]\n",
    "elastic_reg = ElasticNet()\n",
    "Elastic_Regression = GridModeller(elastic_reg,elastic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='log2', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=-1, oob_score=True, random_state=15,\n",
      "           verbose=0, warm_start=False)\n",
      "0.508314801125 {'n_estimators': 25, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.500355616246 {'n_estimators': 50, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.499584569122 {'n_estimators': 100, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.510806186088 {'n_estimators': 25, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.505374595922 {'n_estimators': 50, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.504053217831 {'n_estimators': 100, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.508314801125 {'n_estimators': 25, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.500355616246 {'n_estimators': 50, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.499584569122 {'n_estimators': 100, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.510806186088 {'n_estimators': 25, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.505374595922 {'n_estimators': 50, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.504053217831 {'n_estimators': 100, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "rand_forest_params = [\n",
    "    {'criterion': ['mse'],\n",
    "     'n_estimators': [25,50,100],\n",
    "     'bootstrap': [True],\n",
    "     'max_features': ['log2','sqrt'],\n",
    "     'min_samples_leaf': [2,3],\n",
    "     'oob_score': [True],\n",
    "     'n_jobs': [-1],\n",
    "     'random_state' : [RANDO]\n",
    "    }]\n",
    "rand_forest_reg = RandomForestRegressor()\n",
    "RandomForest_Regression = GridModeller(rand_forest_reg,rand_forest_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "          max_features='log2', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=-1, oob_score=True, random_state=15,\n",
      "          verbose=0, warm_start=False)\n",
      "0.579483440491 {'n_estimators': 25, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.577125958633 {'n_estimators': 50, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.58256832294 {'n_estimators': 100, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.603522936146 {'n_estimators': 25, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.595183659785 {'n_estimators': 50, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.605580513493 {'n_estimators': 100, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'log2', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.579483440491 {'n_estimators': 25, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.577125958633 {'n_estimators': 50, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.58256832294 {'n_estimators': 100, 'criterion': 'mse', 'min_samples_leaf': 2, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.603522936146 {'n_estimators': 25, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.595183659785 {'n_estimators': 50, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n",
      "0.605580513493 {'n_estimators': 100, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_features': 'sqrt', 'n_jobs': -1, 'bootstrap': True, 'random_state': 15, 'oob_score': True}\n"
     ]
    }
   ],
   "source": [
    "# Extremely Random Forest Regression\n",
    "extra_trees_params = [\n",
    "    {'criterion': ['mse'],\n",
    "     'n_estimators': [25,50,100],\n",
    "     'bootstrap': [True],\n",
    "     'max_features': ['log2','sqrt'],\n",
    "     'min_samples_leaf': [2,3],\n",
    "     'oob_score': [True],\n",
    "     'n_jobs': [-1],\n",
    "     'random_state' : [RANDO]\n",
    "    }]\n",
    "extra_trees_reg = ExtraTreesRegressor()\n",
    "ExtraTrees_Regression = GridModeller(extra_trees_reg,extra_trees_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Regression names and models for CV testing\n",
    "names = [\n",
    "    'Linear_Regression',\n",
    "    'SGDRegressor',\n",
    "    'Ridge_Regression',\n",
    "    'Lasso_Regression',\n",
    "    'Elastic_Regression',\n",
    "    'RandomForest_Regression',\n",
    "    'ExtraTrees_Regression'\n",
    "    ] \n",
    "\n",
    "regressors = [\n",
    "    Linear_Regression,\n",
    "    SGD_Regression,\n",
    "    Ridge_Regression,\n",
    "    Lasso_Regression,\n",
    "    Elastic_Regression,\n",
    "    RandomForest_Regression,\n",
    "    ExtraTrees_Regression    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold index: 0 ------------------------------------------\n",
      "\n",
      "Shape of input data for this fold: \n",
      "Data Set: (Observations, Variables)\n",
      "X_train: (472, 12)\n",
      "X_test: (34, 12)\n",
      "y_train: (472,)\n",
      "y_test: (34,)\n",
      "\n",
      "Regression model evaluation for: Linear_Regression\n",
      "  Scikit Learn method: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-24ad9635c559>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0my_test_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         print('Coefficient of determination (R-squared):',\n\u001b[1;32m---> 36\u001b[1;33m               r2_score(y_test, y_test_predict))\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mfold_method_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Run cross-validation testing for optimal models\n",
    "\n",
    "# set up numpy array for storing results\n",
    "cv_results = np.zeros((K, len(names)))\n",
    "\n",
    "kf = KFold(n_splits = K, shuffle=False, random_state = RANDOM_SEED)\n",
    "# check the splitting process by looking at fold observation counts\n",
    "index_for_fold = 0  # fold count initialized \n",
    "for train_index, test_index in kf.split(model_data):\n",
    "    print('\\nFold index:', index_for_fold,\n",
    "          '------------------------------------------')\n",
    "#   the structure of modeling data for this study has the\n",
    "#   response variable coming first and explanatory variables later          \n",
    "#   so 1:model_data.shape[1] slices for explanatory variables\n",
    "#   and 0 is the index for the response variable    \n",
    "    X_train = model_data[train_index, 1:model_data.shape[1]+1]\n",
    "    X_test = model_data[test_index, 1:model_data.shape[1]+1]\n",
    "    y_train = model_data[train_index, 0]\n",
    "    y_test = model_data[test_index, 0]   \n",
    "    print('\\nShape of input data for this fold:',\n",
    "          '\\nData Set: (Observations, Variables)')\n",
    "    print('X_train:', X_train.shape)\n",
    "    print('X_test:',X_test.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "    print('y_test:',y_test.shape)\n",
    "\n",
    "    index_for_method = 0  # initialize\n",
    "    for name, reg_model in zip(names, regressors):\n",
    "        print('\\nRegression model evaluation for:', name)\n",
    "        print('  Scikit Learn method:', reg_model)\n",
    "        reg_model.fit(X_train, y_train)  # fit on the train set for this fold\n",
    "        \n",
    "        # evaluate on the test set for this fold\n",
    "        y_test_predict = reg_model.predict(X_test)\n",
    "        print('Coefficient of determination (R-squared):',\n",
    "              r2_score(y_test, y_test_predict))\n",
    "        fold_method_result = sqrt(mean_squared_error(y_test, y_test_predict))\n",
    "        \n",
    "        print(reg_model.get_params(deep=True))\n",
    "        print('Root mean-squared error:', fold_method_result)\n",
    "        cv_results[index_for_fold, index_for_method] = fold_method_result\n",
    "        index_for_method += 1\n",
    "  \n",
    "    index_for_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# update and print results from CV testing\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "cv_results_df.columns = names\n",
    "\n",
    "print('\\n----------------------------------------------')\n",
    "print('Average results from ', K, '-fold cross-validation\\n',\n",
    "      'in standardized units (mean 0, standard deviation 1)\\n',\n",
    "      '\\nMethod               Root mean-squared error', sep = '')     \n",
    "print(cv_results_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compare CV RMSE value to full-sample RMSE values with fitted models\n",
    "training_regs = []\n",
    "for md in regressors:\n",
    "    rmse = sqrt(mean_squared_error(md.fit(X,Y).predict(X),Y))\n",
    "    rmse = float(\"{0:.6f}\".format(rmse))\n",
    "    training_regs.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comparisons = pd.DataFrame(cv_results_df.mean())\n",
    "comparisons = comparisons.rename(index=str, columns={0: \"CV RMSE\"})\n",
    "comparisons[\"Full Training RMSE\"] = training_regs\n",
    "comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# time how long each function takes to run\n",
    "%timeit(Linear_Regression.score(X,Y))\n",
    "%timeit(SGD_Regression.score(X,Y))\n",
    "%timeit(Elastic_Regression.score(X,Y))\n",
    "%timeit(RandomForest_Regression.score(X,Y))\n",
    "%timeit(ExtraTrees_Regression.score(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# identify most important features\n",
    "features = ['crim','zn','indus','chas','nox','rooms','age','dis','rad','tax','ptratio','lstat']\n",
    "feature_importance = ExtraTrees_Regression.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = pd.DataFrame({'Feature':features, 'Importance':feature_importance})\n",
    "f.sort_values('Importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
